# 1. Find and Replace <your-name> with your name seperated with a dash (ex. kyle-payne).
# 2. Replace <your_dbs_endpoint> with your RDS instance endpoint
#    (AWS ex. kyle-payne-bootcamp-postgresql.cs8j7iukogcy.us-east-2.rds.amazonaws.com)
#    (Azure ex. kyle-payne-bootcamp.postgres.database.azure.com)
# 3. If you are running this lab from the Partner AWS account scroll down and comment out the ARN for the Enablement account and remove the
#    comment for the ARN of the Partner account.
# 4. If you are running this lab in Azure: then you need to scroll down to the expose section and do what it says down there.

# Name of the k8s Secret holding the Starburst License file
starburstPlatformLicense: starburstdata

# The enviroment setting is what you'll see on the main Web UI for the ENVIRONMENT name.
# The sharedSecret is not a k8s Secret it is what the coordinator and worker will use
# to confirm internal communications. More can be found in the SEP doc on this.
environment: hamza_lab01
sharedSecret: u70Qhhw9PsZmEgIo7Zqg3kIj3AJZ5/Mnyy5iyjcsgnceM+SSV+APSTisjlFVH

# As a starting best practice always set the requests and limits memmory and CPU to the same thing.
coordinator:
  resources:
    requests:
      memory: "8Gi"
      cpu: 3
    limits:
      memory: "8Gi"

  # This affinity will ensure the coordinator and worker are deployed in the sep node group.
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: app
                operator: In
                values:
                  - sep

  etcFiles:
    properties:
      #access-control.properties: |
      #  access-control.name=ranger
      #  ranger.authentication-type=BASIC
      #  ranger.service-name=starburst-enterprise
      #  ranger.username=starburst_service
      #  ranger.policy-rest-url=http://ranger:6080
      #  ranger.password=St4rburstR0cks!
      #  ranger.policy-refresh-interval=10s
      log.properties: |
        io.trino=DEBUG
      #  org.apache.ranger=DEBUG
      #cache.properties: |
      #  service-database.user=postgres
      #  service-database.password=StarburstR0cks!
      #  service-database.jdbc-url=jdbc:postgresql://<your_dbs_endpoint>:5432/eks_redirections
      #  starburst.user=caching_service
      #  starburst.password=
      #  starburst.jdbc-url=jdbc:trino://coordinator:8080
      #  rules.file=secretRef:cache-rules:cache-rules.json
      #  rules.refresh-period=1m
      #  refresh-initial-delay=1m
      #  refresh-interval=2m
      # config.properties: |
      #   # http-server.authentication.type=PASSWORD
      #   # discovery.uri=http://starburst.spark.svc.cluster.local:8080
      # password-authenticator.properties: |
      #   password-authenticator.name=file
      #   file.password-file=secretRef:starburst-user-database:user-database-file
      #   file.refresh-period=5s
      #   file.auth-token-cache.max-size=1000
  additionalProperties: |
    http-server.authentication.allow-insecure-over-http=true
    http-server.process-forwarded=true
    insights.persistence-enabled=true 
    insights.metrics-persistence-enabled=true
    insights.jdbc.url=jdbc:postgresql://postgresql.spark.svc.cluster.local:5432/postgres
    insights.jdbc.user=postgres
    insights.jdbc.password=oFYzKVE15f
    # Use the following line for Ranger
    #insights.authorized-users=starburst_service
    # Use the following 4 lines for Built-in Access control
    starburst.access-control.enabled=true
    starburst.access-control.audit.enabled=true
    # starburst.audit.access-log.enabled=true
    starburst.access-control.audit.access-log.enabled=true
    starburst.access-control.authorized-users=starburst_service
    # The following is for Data Products
    starburst.data-product.enabled=true
    data-product.starburst-jdbc-url=jdbc:trino://coordinator:8080
    data-product.starburst-user=dataproducts_service
    data-product.starburst-password=

userDatabase:
  enabled: false

# This expose section is for AWS.  Comment it out for Azure (including expose all the way down too the last networking.gke line)
# The scroll down and do what it says for the expose below that is commented out.
expose:
  type: "loadBalancer"
  loadBalancer:
    name: "starburst"
    ports:
      http:
        port: 8443
# annotations:
# Enablement Account ARN for us-east-2
# service.beta.kubernetes.io/aws-load-balancer-ssl-cert: arn:aws:acm:us-east-2:412911485778:certificate/0d7fe57c-e672-423e-a7ee-a5b8c49df9c2
# Enablement Account ARN for eu-west-2
#service.beta.kubernetes.io/aws-load-balancer-ssl-cert: arn:aws:acm:eu-west-2:412911485778:certificate/576440b7-8299-45db-9ac2-cc921cca0b55
# Partner Account ARN for us-east-2
#service.beta.kubernetes.io/aws-load-balancer-ssl-cert: arn:aws:acm:us-east-2:594246526251:certificate/52ad9f0e-a9a5-4c7c-bc59-f3a405747dfb
# service.beta.kubernetes.io/aws-load-balancer-backend-protocol: http
# If you want the LB to have an internal IP and not a public facing one remove the comment below for your cloud.
# service.beta.kubernetes.io/aws-load-balancer-internal: "true"
#      service.beta.kubernetes.io/azure-load-balancer-internal: "true"
#  networking.gke.io/load-balancer-type: "Internal"

# 1. Replace <azure-dns-zone> with the Azure DNS Zone created for your cluster.
# 2. Remove the commments for this expose section (including expose all the way down to and including the pathType line)
# expose:
#   type: "ingress"
#   ingress:
#     annotations:
#       cert-manager.io/cluster-issuer: letsencrypt-campus
#       kubernetes.io/ingress.class: ngnix
#       kubernetes.io/tls-acme: "true"
#       nginx.ingress.kubernetes.io/proxy-body-size: "0"
#     # The host name below must be unique in the DNS domain you are entering it into.
#     host: starburstnemo.campus.clusterdiali.me
#     ingressName: "starburst-ingress"
#     serviceName: "starburst"
#     servicePort: 8443
#     ingressClassName:
#     tls:
#       enabled: true
#       secretName: starburst.campus.clusterdiali.me-tls
#     path: "/"
#     pathType: Prefix

worker:
  replicas: 1
  #autoscaling:
  #  enabled: true
  #  minReplicas: 1
  #  maxReplicas: 3
  targetCPUUtilizationPercentage: 80 # default is 80
  deploymentTerminationGracePeriodSeconds: 10 # default is 300; it is actually how long the graceful shutdown waits after it receives the SIGTERM
  starburstWorkerShutdownGracePeriodSeconds: 120 # default is 120
  resources:
    requests:
      memory: "8Gi"
      cpu: 3
    limits:
      memory: "8Gi"

  # This affinity will ensure the coordinator and worker are deployed in the sep node group.
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: app
                operator: In
                values:
                  - sep
